{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0mSMpeGI7wKCJUUwYL8Wg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monimoreno2905/SegundoParcial/blob/main/RedDependencia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. LIBRERIAS Y FUNCIONES GENERALES"
      ],
      "metadata": {
        "id": "jWWXsFjw-iUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# en este contexto numpy se utiliza para hacer algunas operaciones matemáticas y definir arreglos\n",
        "import numpy as np\n",
        "#En este ejercicio básicamente se utiliza para manipular directorios\n",
        "import os\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Con esto se garantiza que produzcan los mismos resultados cada vez que se ejecuta el código\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Librerias para la generación de gráficas\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers, Model"
      ],
      "metadata": {
        "id": "Pv5QPWbbnfFp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x8iGAK3Om_Ih"
      },
      "outputs": [],
      "source": [
        "#Grafica imágenes originales vs reconstruidas del mnist después de aplicar el modelo encoder, decoder\n",
        "#Los datos que se le ingresa son: el modelo de reconstrucción, las imágenes originales de las cuales siempre se van a graficar cinco\n",
        "def show_reconstructions(model, images, n_images=5):\n",
        "    reconstructions = model.predict(images[:n_images]) #aplica el modelo de autoencoer para sacar imagenes reconstruidas\n",
        "    fig = plt.figure(figsize=(n_images * 1.5, 3)) #Establece los parámetros de la figura como por ejemplo el tamaño\n",
        "    for image_index in range(n_images): #En cada iteración, dibuja la imagen original y su reconstrucción correspondiente en la figura.\n",
        "        plt.subplot(2, n_images, 1 + image_index) #grafica imágenes originales\n",
        "        plot_image(images[image_index])\n",
        "        plt.subplot(2, n_images, 1 + n_images + image_index) #grafica reconstrucciones\n",
        "        plot_image(reconstructions[image_index])\n",
        "\n",
        "#esta función se utiliza internamente en la función show_reconstructions para graficar las imagenes reconstruidas\n",
        "def plot_image(image):\n",
        "    plt.imshow(image, cmap=\"binary\")\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. CARGA DE DATOS"
      ],
      "metadata": {
        "id": "Xbm8rcDq-omD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full.astype(np.float32) / 255 #normalización de los datos\n",
        "X_test = X_test.astype(np.float32) / 255\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:] #Se toman solo algunos datos, no todos\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]"
      ],
      "metadata": {
        "id": "R0CfOkF4nOCq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d9e04ae-99b5-4cad-cc6d-9835476747ec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. FUNCIONES PARA CALCULAR F Y G de acuerdo a las ecuaciones del Kernel reproductor.\n",
        "\n",
        "Para no tener problemas en las dimensiones para realizar operaciones más adelante en la función de costos, tenemos;\n",
        "\n",
        "$f=X^{T}Hα  \\in R^{1x1}$\n",
        "\n",
        "$g=Y^{T}Hβ  \\in R^{1x1}$\n",
        "\n",
        "$C{xy}=X^{T}HY ∈ R^{1x1}$\n",
        "\n",
        "y la función de costos evaluada\n",
        "\n",
        "$L(f, g, \\lambda, \\gamma) = -f C_{XY} g + \\frac{\\lambda}{2} \\|f\\|^2_F - 1 + \\frac{\\gamma}{2} \\|g\\|^2_G - 1\n",
        "$"
      ],
      "metadata": {
        "id": "mYk3ZvuU-qLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Clase para calcular f con base a los datos originales\"\"\"\n",
        "class Calculate_f(layers.Layer):\n",
        "    \"\"\"Inicialización\n",
        "       factor_o=0.1: factor de ajuste para el peso o alguna otra operación en la capa,\n",
        "       activation=None: Define la función de activación de la capa. Si no se especifica una activación, el valor por defecto es None, lo que significa que la capa no aplicará ninguna función de activación si no se especifica.\n",
        "    \"\"\"\n",
        "    def __init__(self, factor_o=0.1,activation=None, **kwargs):\n",
        "        super(Calculate_f, self).__init__(**kwargs)\n",
        "        self.factor_o = factor_o\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "    \"\"\"Configura los pesos de la capa perzonalizada (alpha)\n",
        "    El método build se utiliza en capas personalizadas de Keras para definir las variables que dependen de la forma de entrada (input_shape).\n",
        "    Se llama cuando la capa se conecta por primera vez a los datos, ya que hasta ese momento, Keras no conoce las dimensiones exactas de entrada.\n",
        "    \"\"\"\n",
        "    def build(self, input_shape):\n",
        "        n = input_shape[0] #Para saber cuántos datos hay\n",
        "        self.w = self.add_weight( #Este es el método que añade un tensor de pesos llamado w a la capa.\n",
        "            shape=(n, 1), #Define la forma del tensor de pesos (alpha)\n",
        "            initializer=\"random_normal\",\n",
        "            trainable=True,regularizer=tf.keras.regularizers.OrthogonalRegularizer(factor=self.factor_o),\n",
        "            constraint=tf.keras.constraints.max_norm(1.)\n",
        "        )\n",
        "        super(Calculate_f, self).build(input_shape) #Este es el llamado al método build de la clase base\n",
        "    \"\"\"Este método call define cómo se aplica la capa personalizada Calculate_f a los datos de entrada (inputs) durante la ejecución del modelo\"\"\"\n",
        "    def call(self, inputs):\n",
        "        # Convertir n a float32\n",
        "        n = tf.shape(inputs)[0]  # Obtener el tamaño del batch dinámicamente\n",
        "        n = tf.cast(n, tf.float32)\n",
        "        H = tf.eye(n, dtype=tf.float32) - (1/n) * tf.ones((n, n), dtype=tf.float32)  # Se define H de acuerdo a la cantidad de datos\n",
        "        f = tf.linalg.matmul(tf.linalg.matmul(tf.transpose(inputs),H), self.w) #Ecuación de f\n",
        "        if self.activation is not None:\n",
        "            f = self.activation(f)\n",
        "        return f"
      ],
      "metadata": {
        "id": "5qxFFBeBnv9S"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Clase para calcular g\n",
        "Se aplica el proceso anterior pero esta vez para las reconstrucciones que por cierto se despejan de g\n",
        "\"\"\"\n",
        "class Calculate_g(layers.Layer):\n",
        "    \"\"\"Inicialización\n",
        "       factor_o=0.1: factor de ajuste para el peso o alguna otra operación en la capa,\n",
        "       activation=None: Define la función de activación de la capa. Si no se especifica una activación, el valor por defecto es None, lo que significa que la capa no aplicará ninguna función de activación si no se especifica.\n",
        "    \"\"\"\n",
        "    def __init__(self, factor_o=0.1,activation=None, **kwargs):\n",
        "        super(Calculate_g, self).__init__(**kwargs)\n",
        "\n",
        "        self.factor_o = factor_o\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "    \"\"\"Configura los pesos de la capa perzonalizada (beta)\n",
        "    El método build se utiliza en capas personalizadas de Keras para definir las variables que dependen de la forma de entrada (input_shape).\n",
        "    Se llama cuando la capa se conecta por primera vez a los datos, ya que hasta ese momento, Keras no conoce las dimensiones exactas de entrada.\n",
        "    \"\"\"\n",
        "    def build(self, input_shape):\n",
        "        n = input_shape\n",
        "        self.z = self.add_weight( #Este es el método que añade un tensor de pesos llamado w a la capa.\n",
        "            shape=(n, 1), #Define la forma del tensor de pesos (beta)\n",
        "            initializer=\"random_normal\",\n",
        "            trainable=True,regularizer=tf.keras.regularizers.OrthogonalRegularizer(factor=self.factor_o),\n",
        "            constraint=tf.keras.constraints.max_norm(1.)\n",
        "        )\n",
        "        super(Calculate_g, self).build(input_shape) #Este es el llamado al método build de la clase base\n",
        "    \"\"\"Este método call define cómo se aplica la capa personalizada Calculate_g a los datos de entrada (inputs) durante la ejecución del modelo\"\"\"\n",
        "    def call(self, y):\n",
        "        n = tf.shape(y)[0]  # Obtener el tamaño del batch dinámicamente\n",
        "        n = tf.cast(n, tf.float32)\n",
        "        H = tf.eye(n, dtype=tf.float32) - (1/n) * tf.ones((n, n), dtype=tf.float32)  # Definir H según la cantidad de datos\n",
        "        g = tf.linalg.matmul(tf.linalg.matmul(tf.transpose(y),H), self.z) #Se aplica la ecuación de g\n",
        "        if self.activation is not None:\n",
        "            g = self.activation(g)\n",
        "        #Aqui estoy intentando aplicar algo similar al PCA autoencoder que vimos una vez, despejar y a partir de g pero entro en dilema porque para calcular g necesito y\n",
        "        y=tf.linalg.matmul(g,tf.transpose(tf.linalg.matmul(H,self.z)))\n",
        "        y=tf.transpose(y)\n",
        "        return g"
      ],
      "metadata": {
        "id": "Q8pt4pH144_z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. DEFINIR EL MODELO\n",
        "\n",
        "La verdad no se bien como hacer esto, estoy intentando regresar f y g pero tengo el problema del despeje que hice de y en Calculate_g"
      ],
      "metadata": {
        "id": "bKL6MtUAEGgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(Model):\n",
        "    \"\"\"Este código define el constructor (__init__) para una clase llamada Autoencoder\"\"\"\n",
        "    def __init__(self, encoding_dim,factor_o=0.1):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoding_dim = encoding_dim #encoding_dim: Especifica la dimensión del espacio latente donde se codificarán los datos\n",
        "        self.factor_o=factor_o\n",
        "        # Encoder layers\n",
        "        self.encoder_input_layer = layers.Flatten()\n",
        "\n",
        "        # Decoder layers will be initialized in build()\n",
        "        #Aquí se define una capa personalizada que será utilizada para conectar el encoder y el decoder.\n",
        "        self.encoder_decoder_transpose = Calculate_g(self.encoding_dim, factor_o=self.factor_o,activation='linear')\n",
        "        self.decoder_output_layer = None\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Now that we have the input shape, initialize decoder layers\n",
        "        self.encoder_decoder_transpose.build(input_shape[1]*input_shape[2])\n",
        "        self.decoder_output_layer = layers.Reshape(input_shape[1:])\n",
        "        super().build(input_shape)\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.encoder_input_layer(inputs)\n",
        "        x = self.encoder_decoder_transpose(x)\n",
        "        g = self.decoder_output_layer(x)\n",
        "        return g"
      ],
      "metadata": {
        "id": "wg8b1_solJrT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Función para definir el loss\n",
        "def loss_custom(f,g,Cxy):\n",
        "  lambda_param = 0.1\n",
        "  gamma_param = 0.1\n",
        "  L = -tf.matmul(tf.matmul(f, Cxy), g) + \\\n",
        "    (lambda_param / 2) * tf.square(f) + \\\n",
        "    (gamma_param / 2) * tf.square(g)"
      ],
      "metadata": {
        "id": "HF-TJ9WbEstD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the autoencoder\n",
        "encoding_dim = 64\n",
        "input_shape = (None, 28, 28, 1)\n",
        "factor_o = 0.1\n",
        "#optimizer=keras.optimizers.SGD(learning_rate=0.001)\n",
        "#optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.1)\n",
        "pcautoencoder = Autoencoder(encoding_dim)\n",
        "pcautoencoder.build(input_shape)\n",
        "pcautoencoder.compile(optimizer='adam', loss=loss_custom) #Se utiliza la función de costos personalizada\n",
        "pcautoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "wY5pnzp8lxE6",
        "outputId": "1896f54f-6263-45de-b806-552c7f91657c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Calculate_g.__init__() got multiple values for argument 'factor_o'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-a123f007c637>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#optimizer=keras.optimizers.SGD(learning_rate=0.001)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpcautoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mpcautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpcautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_custom\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-26b2fe173c41>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, encoding_dim, factor_o)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Decoder layers will be initialized in build()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#Aquí se define una capa personalizada que será utilizada para conectar el encoder y el decoder.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_decoder_transpose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCalculate_g\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor_o\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactor_o\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_output_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Calculate_g.__init__() got multiple values for argument 'factor_o'"
          ]
        }
      ]
    }
  ]
}